{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook dedicado a mostrar distintas operaciones sobre columnas de un DataFrame:\n",
    "- Eliminar columnas\n",
    "- Añadir columnas\n",
    "- Actualizar columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.36:4043\n",
       "SparkContext available as 'sc' (version = 3.0.2, master = local[*], app id = local-1615722820654)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n",
       "columns: Seq[String] = List(name, age, weight, height)\n",
       "data: Seq[(String, Int, Int, Double)] = List((Jose,40,74,1.63), (María Isabel,38,58,1.65), (Antonio,27,60,1.68), (Norma,63,65,1.54))\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "val columns = Seq(\"name\",\"age\",\"weight\", \"height\")\n",
    "val data = Seq((\"Jose\", 40, 74, 1.63), (\"María Isabel\", 38, 58, 1.65), (\"Antonio\", 27, 60, 1.68), (\"Norma\", 63, 65, 1.54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- weight: integer (nullable = false)\n",
      " |-- height: double (nullable = false)\n",
      "\n",
      "+------------+---+------+------+\n",
      "|        name|age|weight|height|\n",
      "+------------+---+------+------+\n",
      "|        Jose| 40|    74|  1.63|\n",
      "|María Isabel| 38|    58|  1.65|\n",
      "|     Antonio| 27|    60|  1.68|\n",
      "|       Norma| 63|    65|  1.54|\n",
      "+------------+---+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [name: string, age: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Creando DF a partir de un Seq de datos utilizando implicits -> Seq.toDF\n",
    "// El schema es inferido y los nombres de columnas son pasados como parametro\n",
    "val df = data.toDF(columns:_*)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------+\n",
      "|        name|age|height|\n",
      "+------------+---+------+\n",
      "|        Jose| 40|  1.63|\n",
      "|María Isabel| 38|  1.65|\n",
      "|     Antonio| 27|  1.68|\n",
      "|       Norma| 63|  1.54|\n",
      "+------------+---+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df1: org.apache.spark.sql.DataFrame = [name: string, age: int ... 1 more field]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Seleccionando columnas\n",
    "val df1 = df.select(\"name\", \"age\", \"height\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------+\n",
      "|        name|weight|height|\n",
      "+------------+------+------+\n",
      "|        Jose|    74|  1.63|\n",
      "|María Isabel|    58|  1.65|\n",
      "|     Antonio|    60|  1.68|\n",
      "|       Norma|    65|  1.54|\n",
      "+------------+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfDrop: org.apache.spark.sql.DataFrame = [name: string, weight: int ... 1 more field]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Eliminar columna\n",
    "val dfDrop = df.drop(\"age\")\n",
    "dfDrop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------+------+------+\n",
      "|        name|age|weight|height|  type|\n",
      "+------------+---+------+------+------+\n",
      "|        Jose| 40|    74|  1.63|Person|\n",
      "|María Isabel| 38|    58|  1.65|Person|\n",
      "|     Antonio| 27|    60|  1.68|Person|\n",
      "|       Norma| 63|    65|  1.54|Person|\n",
      "+------------+---+------+------+------+\n",
      "\n",
      "+------------+---+------+------+------+------+\n",
      "|        name|age|weight|height|  type|   sex|\n",
      "+------------+---+------+------+------+------+\n",
      "|        Jose| 40|    74|  1.63|Person|  Male|\n",
      "|María Isabel| 38|    58|  1.65|Person|Female|\n",
      "|     Antonio| 27|    60|  1.68|Person|  Male|\n",
      "|       Norma| 63|    65|  1.54|Person|Female|\n",
      "+------------+---+------+------+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{lit, when, col}\n",
       "df2: org.apache.spark.sql.DataFrame = [name: string, age: int ... 3 more fields]\n",
       "df3: org.apache.spark.sql.DataFrame = [name: string, age: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{lit, when, col}\n",
    "\n",
    "// Añadir columna con valor constante\n",
    "val df2 = df.withColumn(\"type\", lit(\"Person\"))\n",
    "df2.show()\n",
    "\n",
    "// Añadir columna con valor dinamico dependiendo del valor de una columna existente usando la funcion \"when\"\n",
    "val df3 = df2.withColumn(\"sex\", when(col(\"name\") === \"Jose\" || col(\"name\") === \"Antonio\", \"Male\").otherwise(\"Female\"))\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------+------+-------+------+\n",
      "|        name|age|weight|height|   type|   sex|\n",
      "+------------+---+------+------+-------+------+\n",
      "|        Jose| 40|    74|  1.63|Persona|  Male|\n",
      "|María Isabel| 38|    58|  1.65|Persona|Female|\n",
      "|     Antonio| 27|    60|  1.68|Persona|  Male|\n",
      "|       Norma| 63|    65|  1.54|Persona|Female|\n",
      "+------------+---+------+------+-------+------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- weight: integer (nullable = false)\n",
      " |-- height: double (nullable = false)\n",
      " |-- type: string (nullable = false)\n",
      " |-- sex: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df4: org.apache.spark.sql.DataFrame = [name: string, age: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Actualizar column\n",
    "val df4 = df3.withColumn(\"type\", lit(\"Persona\"))\n",
    "df4.show()\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------+------+-------+------+\n",
      "|        name|age|weight|height|   type|   sex|\n",
      "+------------+---+------+------+-------+------+\n",
      "|        Jose| 40|  74.0|  1.63|Persona|  Male|\n",
      "|María Isabel| 38|  58.0|  1.65|Persona|Female|\n",
      "|     Antonio| 27|  60.0|  1.68|Persona|  Male|\n",
      "|       Norma| 63|  65.0|  1.54|Persona|Female|\n",
      "+------------+---+------+------+-------+------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- weight: double (nullable = false)\n",
      " |-- height: double (nullable = false)\n",
      " |-- type: string (nullable = false)\n",
      " |-- sex: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df5: org.apache.spark.sql.DataFrame = [name: string, age: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Actualizar columna con valor dinamico dependiendo del valor de una columna existente aplicandole a esta un cast\n",
    "// Podemos ver como cambia el schema del DF\n",
    "val df5 = df4.withColumn(\"weight\", col(\"weight\").cast(\"Double\"))\n",
    "df5.show()\n",
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------+------+-------+------+\n",
      "|        name|age|weight|height|   tipo|   sex|\n",
      "+------------+---+------+------+-------+------+\n",
      "|        Jose| 40|    74|  1.63|Persona|  Male|\n",
      "|María Isabel| 38|    58|  1.65|Persona|Female|\n",
      "|     Antonio| 27|    60|  1.68|Persona|  Male|\n",
      "|       Norma| 63|    65|  1.54|Persona|Female|\n",
      "+------------+---+------+------+-------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df6: org.apache.spark.sql.DataFrame = [name: string, age: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Renombrado de columna\n",
    "val df6 = df4.withColumnRenamed(\"type\", \"tipo\")\n",
    "df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- newName: string (nullable = true)\n",
      " |-- newAge: integer (nullable = false)\n",
      " |-- newWeight: integer (nullable = false)\n",
      " |-- newHeight: double (nullable = false)\n",
      "\n",
      "+------------+------+---------+---------+\n",
      "|     newName|newAge|newWeight|newHeight|\n",
      "+------------+------+---------+---------+\n",
      "|        Jose|    40|       74|     1.63|\n",
      "|María Isabel|    38|       58|     1.65|\n",
      "|     Antonio|    27|       60|     1.68|\n",
      "|       Norma|    63|       65|     1.54|\n",
      "+------------+------+---------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newColumns: Seq[String] = List(newName, newAge, newWeight, newHeight)\n",
       "df7: org.apache.spark.sql.DataFrame = [newName: string, newAge: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Renombrado de multiples columnas\n",
    "val newColumns = Seq(\"newName\",\"newAge\",\"newWeight\", \"newHeight\")\n",
    "val df7 = df.toDF(newColumns:_*)\n",
    "df7.printSchema()\n",
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Project [name#13, age#14, weight#15, height#16, tipo#193]\n",
      "+- Project [name#13, age#14, weight#15, height#16, type#129 AS tipo#193, sex#97]\n",
      "   +- Project [name#13, age#14, weight#15, height#16, Persona AS type#129, sex#97]\n",
      "      +- Project [name#13, age#14, weight#15, height#16, type#70, CASE WHEN ((name#13 = Jose) OR (name#13 = Antonio)) THEN Male ELSE Female END AS sex#97]\n",
      "         +- Project [name#13, age#14, weight#15, height#16, Person AS type#70]\n",
      "            +- Project [_1#4 AS name#13, _2#5 AS age#14, _3#6 AS weight#15, _4#7 AS height#16]\n",
      "               +- LocalRelation [_1#4, _2#5, _3#6, _4#7]\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "name: string, age: int, weight: int, height: double, tipo: string\n",
      "Project [name#13, age#14, weight#15, height#16, tipo#193]\n",
      "+- Project [name#13, age#14, weight#15, height#16, type#129 AS tipo#193, sex#97]\n",
      "   +- Project [name#13, age#14, weight#15, height#16, Persona AS type#129, sex#97]\n",
      "      +- Project [name#13, age#14, weight#15, height#16, type#70, CASE WHEN ((name#13 = Jose) OR (name#13 = Antonio)) THEN Male ELSE Female END AS sex#97]\n",
      "         +- Project [name#13, age#14, weight#15, height#16, Person AS type#70]\n",
      "            +- Project [_1#4 AS name#13, _2#5 AS age#14, _3#6 AS weight#15, _4#7 AS height#16]\n",
      "               +- LocalRelation [_1#4, _2#5, _3#6, _4#7]\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "LocalRelation [name#13, age#14, weight#15, height#16, tipo#193]\n",
      "\n",
      "== Physical Plan ==\n",
      "LocalTableScan [name#13, age#14, weight#15, height#16, tipo#193]\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias('name, None), unresolvedalias('age, None), unresolvedalias('weight, None), unresolvedalias('height, None), unresolvedalias('tipo, None)]\n",
      "+- Project [name#13, age#14, weight#15, height#16, type#129 AS tipo#193, sex#97]\n",
      "   +- Project [name#13, age#14, weight#15, height#16, Persona AS type#129, sex#97]\n",
      "      +- Project [name#13, age#14, weight#15, height#16, type#70, CASE WHEN ((name#13 = Jose) OR (name#13 = Antonio)) THEN Male ELSE Female END AS sex#97]\n",
      "         +- Project [name#13, age#14, weight#15, height#16, Person AS type#70]\n",
      "            +- Project [_1#4 AS name#13, _2#5 AS age#14, _3#6 AS weight#15, _4#7 AS height#16]\n",
      "               +- LocalRelation [_1#4, _2#5, _3#6, _4#7]\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "name: string, age: int, weight: int, height: double, tipo: string\n",
      "Project [name#13, age#14, weight#15, height#16, tipo#193]\n",
      "+- Project [name#13, age#14, weight#15, height#16, type#129 AS tipo#193, sex#97]\n",
      "   +- Project [name#13, age#14, weight#15, height#16, Persona AS type#129, sex#97]\n",
      "      +- Project [name#13, age#14, weight#15, height#16, type#70, CASE WHEN ((name#13 = Jose) OR (name#13 = Antonio)) THEN Male ELSE Female END AS sex#97]\n",
      "         +- Project [name#13, age#14, weight#15, height#16, Person AS type#70]\n",
      "            +- Project [_1#4 AS name#13, _2#5 AS age#14, _3#6 AS weight#15, _4#7 AS height#16]\n",
      "               +- LocalRelation [_1#4, _2#5, _3#6, _4#7]\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "LocalRelation [name#13, age#14, weight#15, height#16, tipo#193]\n",
      "\n",
      "== Physical Plan ==\n",
      "LocalTableScan [name#13, age#14, weight#15, height#16, tipo#193]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Diferencia entre drop y select\n",
    "// Eliminar una (o varias) columna(s) se puede conseguir mediente un drop o un select de un subconjunto del total de columnas\n",
    "\n",
    "// NOTA: De ambos se puede apreciar que el plan logico y fisico es casi identico\n",
    "df6.drop(\"sex\").explain(true)\n",
    "df6.select(\"name\", \"age\", \"weight\", \"height\", \"tipo\").explain(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Project [name#13, age#14, weight#15, height#16, tipo#193, sex#97, newColumn1#260, 2 AS newColumn2#268]\n",
      "+- Project [name#13, age#14, weight#15, height#16, tipo#193, sex#97, 1 AS newColumn1#260]\n",
      "   +- Project [name#13, age#14, weight#15, height#16, type#129 AS tipo#193, sex#97]\n",
      "      +- Project [name#13, age#14, weight#15, height#16, Persona AS type#129, sex#97]\n",
      "         +- Project [name#13, age#14, weight#15, height#16, type#70, CASE WHEN ((name#13 = Jose) OR (name#13 = Antonio)) THEN Male ELSE Female END AS sex#97]\n",
      "            +- Project [name#13, age#14, weight#15, height#16, Person AS type#70]\n",
      "               +- Project [_1#4 AS name#13, _2#5 AS age#14, _3#6 AS weight#15, _4#7 AS height#16]\n",
      "                  +- LocalRelation [_1#4, _2#5, _3#6, _4#7]\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "name: string, age: int, weight: int, height: double, tipo: string, sex: string, newColumn1: int, newColumn2: int\n",
      "Project [name#13, age#14, weight#15, height#16, tipo#193, sex#97, newColumn1#260, 2 AS newColumn2#268]\n",
      "+- Project [name#13, age#14, weight#15, height#16, tipo#193, sex#97, 1 AS newColumn1#260]\n",
      "   +- Project [name#13, age#14, weight#15, height#16, type#129 AS tipo#193, sex#97]\n",
      "      +- Project [name#13, age#14, weight#15, height#16, Persona AS type#129, sex#97]\n",
      "         +- Project [name#13, age#14, weight#15, height#16, type#70, CASE WHEN ((name#13 = Jose) OR (name#13 = Antonio)) THEN Male ELSE Female END AS sex#97]\n",
      "            +- Project [name#13, age#14, weight#15, height#16, Person AS type#70]\n",
      "               +- Project [_1#4 AS name#13, _2#5 AS age#14, _3#6 AS weight#15, _4#7 AS height#16]\n",
      "                  +- LocalRelation [_1#4, _2#5, _3#6, _4#7]\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "LocalRelation [name#13, age#14, weight#15, height#16, tipo#193, sex#97, newColumn1#260, newColumn2#268]\n",
      "\n",
      "== Physical Plan ==\n",
      "LocalTableScan [name#13, age#14, weight#15, height#16, tipo#193, sex#97, newColumn1#260, newColumn2#268]\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias('name, None), unresolvedalias('age, None), unresolvedalias('weight, None), unresolvedalias('height, None), unresolvedalias('tipo, None), unresolvedalias('sex, None), 1 AS newColumn1#277, 2 AS newColumn2#278]\n",
      "+- Project [name#13, age#14, weight#15, height#16, type#129 AS tipo#193, sex#97]\n",
      "   +- Project [name#13, age#14, weight#15, height#16, Persona AS type#129, sex#97]\n",
      "      +- Project [name#13, age#14, weight#15, height#16, type#70, CASE WHEN ((name#13 = Jose) OR (name#13 = Antonio)) THEN Male ELSE Female END AS sex#97]\n",
      "         +- Project [name#13, age#14, weight#15, height#16, Person AS type#70]\n",
      "            +- Project [_1#4 AS name#13, _2#5 AS age#14, _3#6 AS weight#15, _4#7 AS height#16]\n",
      "               +- LocalRelation [_1#4, _2#5, _3#6, _4#7]\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "name: string, age: int, weight: int, height: double, tipo: string, sex: string, newColumn1: int, newColumn2: int\n",
      "Project [name#13, age#14, weight#15, height#16, tipo#193, sex#97, 1 AS newColumn1#277, 2 AS newColumn2#278]\n",
      "+- Project [name#13, age#14, weight#15, height#16, type#129 AS tipo#193, sex#97]\n",
      "   +- Project [name#13, age#14, weight#15, height#16, Persona AS type#129, sex#97]\n",
      "      +- Project [name#13, age#14, weight#15, height#16, type#70, CASE WHEN ((name#13 = Jose) OR (name#13 = Antonio)) THEN Male ELSE Female END AS sex#97]\n",
      "         +- Project [name#13, age#14, weight#15, height#16, Person AS type#70]\n",
      "            +- Project [_1#4 AS name#13, _2#5 AS age#14, _3#6 AS weight#15, _4#7 AS height#16]\n",
      "               +- LocalRelation [_1#4, _2#5, _3#6, _4#7]\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "LocalRelation [name#13, age#14, weight#15, height#16, tipo#193, sex#97, newColumn1#277, newColumn2#278]\n",
      "\n",
      "== Physical Plan ==\n",
      "LocalTableScan [name#13, age#14, weight#15, height#16, tipo#193, sex#97, newColumn1#277, newColumn2#278]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Diferencia entre withColumn y select\n",
    "// Añadir una (o varias) columna(s) se puede conseguir mediente un withColumn (como pudimos ver antes)\n",
    "// o mediante un select donde se añada la nueva columna\n",
    "\n",
    "// NOTA: De ambos se puede apreciar que el plan logico y fisico es parecido, pero es más óptimo el uso del select\n",
    "// ya que el primero añade una projection adicional por cada llamada al método withColumn por lo cual de hacer un uso excesivo de este\n",
    "// se podría derivar en un StackOverflowException\n",
    "df6.withColumn(\"newColumn1\", lit(1)).withColumn(\"newColumn2\", lit(2))explain(true)\n",
    "df6.select(col(\"name\"), col(\"age\"), col(\"weight\"), col(\"height\"), col(\"tipo\"), col(\"sex\"), lit(1).as(\"newColumn1\"), lit(2).as(\"newColumn2\")).explain(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
