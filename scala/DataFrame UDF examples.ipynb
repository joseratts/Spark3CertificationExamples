{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook dedicado a mostrar ejemplos de creación e invocación de UDFs en spark sobre DataFrames y Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.36:4042\n",
       "SparkContext available as 'sc' (version = 3.0.2, master = local[*], app id = local-1615757241189)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|  X|f(x)=2*X|\n",
      "+---+--------+\n",
      "|  0|       0|\n",
      "|  1|       2|\n",
      "|  2|       4|\n",
      "|  3|       6|\n",
      "|  4|       8|\n",
      "|  5|      10|\n",
      "|  6|      12|\n",
      "|  7|      14|\n",
      "|  8|      16|\n",
      "|  9|      18|\n",
      "| 10|      20|\n",
      "| 11|      22|\n",
      "| 12|      24|\n",
      "| 13|      26|\n",
      "| 14|      28|\n",
      "| 15|      30|\n",
      "| 16|      32|\n",
      "| 17|      34|\n",
      "| 18|      36|\n",
      "| 19|      38|\n",
      "+---+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n",
       "columns: Seq[String] = List(X, f(x)=2*X)\n",
       "numRecords: Int = 100\n",
       "df: org.apache.spark.sql.DataFrame = [X: int, f(x)=2*X: int]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "val columns = Seq(\"X\",\"f(x)=2*X\")\n",
    "val numRecords = 100\n",
    "val df = spark.createDataFrame((0 until numRecords).map(x => (x, 2*x))).toDF(columns:_*)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "squared: Long => Long = $Lambda$2446/181673764@12050e01\n",
       "res1: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$2446/181673764@12050e01,LongType,List(Some(class[value[0]: bigint])),Some(squared),false,true)\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val squared = (y: Long) => {\n",
    "  y * y\n",
    "}\n",
    "\n",
    "spark.udf.register(\"squared\", squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|  X|  Y| Y^2|\n",
      "+---+---+----+\n",
      "|  0|  0|   0|\n",
      "|  1|  2|   4|\n",
      "|  2|  4|  16|\n",
      "|  3|  6|  36|\n",
      "|  4|  8|  64|\n",
      "|  5| 10| 100|\n",
      "|  6| 12| 144|\n",
      "|  7| 14| 196|\n",
      "|  8| 16| 256|\n",
      "|  9| 18| 324|\n",
      "| 10| 20| 400|\n",
      "| 11| 22| 484|\n",
      "| 12| 24| 576|\n",
      "| 13| 26| 676|\n",
      "| 14| 28| 784|\n",
      "| 15| 30| 900|\n",
      "| 16| 32|1024|\n",
      "| 17| 34|1156|\n",
      "| 18| 36|1296|\n",
      "| 19| 38|1444|\n",
      "+---+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// UDFs en SparkSQL\n",
    "\n",
    "df.createOrReplaceTempView(\"testUDF\")\n",
    "\n",
    "spark.sql(\"SELECT X, `f(x)=2*X` as Y, squared(`f(x)=2*X`) as `Y^2` FROM testUDF\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|  X|  Y| Y^2|\n",
      "+---+---+----+\n",
      "|  0|  0|   0|\n",
      "|  1|  2|   4|\n",
      "|  2|  4|  16|\n",
      "|  3|  6|  36|\n",
      "|  4|  8|  64|\n",
      "|  5| 10| 100|\n",
      "|  6| 12| 144|\n",
      "|  7| 14| 196|\n",
      "|  8| 16| 256|\n",
      "|  9| 18| 324|\n",
      "| 10| 20| 400|\n",
      "| 11| 22| 484|\n",
      "| 12| 24| 576|\n",
      "| 13| 26| 676|\n",
      "| 14| 28| 784|\n",
      "| 15| 30| 900|\n",
      "| 16| 32|1024|\n",
      "| 17| 34|1156|\n",
      "| 18| 36|1296|\n",
      "| 19| 38|1444|\n",
      "+---+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, udf}\n",
       "squaredOnDF: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$2446/181673764@12050e01,LongType,List(Some(class[value[0]: bigint])),None,false,true)\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// UDFs en DataFrames\n",
    "\n",
    "import org.apache.spark.sql.functions.{col, udf}\n",
    "\n",
    "val squaredOnDF = udf(squared)\n",
    "\n",
    "df.select(col(\"X\"), col(\"`f(x)=2*X`\").as(\"Y\"), squaredOnDF(col(\"`f(x)=2*X`\")).as(\"Y^2\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------+------+\n",
      "|        name|age|weight|height|\n",
      "+------------+---+------+------+\n",
      "|        Jose| 40|    74|  1.63|\n",
      "|María Isabel| 38|    58|  1.65|\n",
      "|     Antonio| 27|    60|  1.68|\n",
      "|       Norma| 63|    65|  1.54|\n",
      "+------------+---+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "columns: Seq[String] = List(name, age, weight, height)\n",
       "data: Seq[(String, Int, Int, Double)] = List((Jose,40,74,1.63), (María Isabel,38,58,1.65), (Antonio,27,60,1.68), (Norma,63,65,1.54))\n",
       "df: org.apache.spark.sql.DataFrame = [name: string, age: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val columns = Seq(\"name\",\"age\",\"weight\", \"height\")\n",
    "val data = Seq((\"Jose\", 40, 74, 1.63), (\"María Isabel\", 38, 58, 1.65), (\"Antonio\", 27, 60, 1.68), (\"Norma\", 63, 65, 1.54))\n",
    "val df = data.toDF(columns:_*)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------+------+---------+\n",
      "|        name|age|weight|height|      IMC|\n",
      "+------------+---+------+------+---------+\n",
      "|        Jose| 40|    74|  1.63|45.398773|\n",
      "|María Isabel| 38|    58|  1.65|35.151516|\n",
      "|     Antonio| 27|    60|  1.68|35.714287|\n",
      "|       Norma| 63|    65|  1.54|42.207794|\n",
      "+------------+---+------+------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "calculate_imc: (Integer, Float) => Float = $Lambda$2595/608032175@3ca618b8\n",
       "imc: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$2595/608032175@3ca618b8,FloatType,List(Some(class[value[0]: int]), Some(class[value[0]: float])),None,false,true)\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// UDFs en DataFrames\n",
    "// función para el calculo del indice de masa corporal\n",
    "val calculate_imc = (weight: Integer, height: Float) => weight/height\n",
    "val imc = udf(calculate_imc)\n",
    "\n",
    "df.select(col(\"name\"), col(\"age\"), col(\"weight\"), col(\"height\"), imc(col(\"weight\"), col(\"height\")).as(\"IMC\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------+------+---------+\n",
      "|        name|age|weight|height|      IMC|\n",
      "+------------+---+------+------+---------+\n",
      "|        Jose| 40|    74|  1.63|45.398773|\n",
      "|María Isabel| 38|    58|  1.65|35.151516|\n",
      "|     Antonio| 27|    60|  1.68|35.714287|\n",
      "|       Norma| 63|    65|  1.54|42.207794|\n",
      "+------------+---+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// UDFs en SparkSQL\n",
    "// función para el calculo del indice de masa corporal\n",
    "spark.udf.register(\"imc\", calculate_imc)\n",
    "\n",
    "df.createOrReplaceTempView(\"testUDF2\")\n",
    "spark.sql(\"SELECT name, age, weight, height, imc(weight, height) as IMC FROM testUDF2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
